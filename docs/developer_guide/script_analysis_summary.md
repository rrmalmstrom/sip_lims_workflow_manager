# Analysis of Python Pooling Workflow Scripts

This document summarizes the function and workflow of the Python scripts used in the library pooling process. The goal is to provide a clear overview for refactoring and modification discussions.

---

## 1. `scripts/complete.clarity.pool.prep.sheet.py`

### High-Level Summary
This is the **first major step** in the workflow. It automates the preparation of a Clarity LIMS pooling worksheet by calculating the required volumes of individual DNA libraries to create balanced pools. It reads data from a local SQLite database and an Excel file containing pooling assignments, performs calculations, and generates an updated Clarity pooling prep sheet (`.xlsx`), an updated SQLite database, and a CSV file.

### Data Flow
- **Inputs:**
    - `lib_info_submitted_to_clarity.db`: A SQLite database containing information about all the individual libraries.
    - `assign_pool_number_sheet.xlsx`: An Excel file where a user manually assigns libraries to specific pools and defines constants (e.g., target mass, transfer volumes).
    - `PoolingPrep_...xlsx`: A template file downloaded from Clarity LIMS.
- **Outputs:**
    - `autofilled_PoolingPrep_...xlsx`: The main output, a completed Clarity sheet ready for upload.
    - `lib_info_submitted_to_clarity.db`: The SQLite database is **overwritten** with updated information, including calculated transfer volumes and pool assignments.
    - `lib_info_submitted_to_clarity.csv`: A CSV version of the updated database.

### Key Functions
- `readSQLdb()`: Reads the initial library data from the SQLite database.
- `assignPool()`: Assigns libraries to pools based on the Excel input and validates for index collisions and plate limits.
- `getLibMass()` & `getLibVolumes()`: Calculate the required mass and final transfer volume for each library to achieve an equimolar pool.
- `fillPoolPrepSheet()`: Populates the Clarity `PoolingPrep_...xlsx` template with the calculated values.
- `createSQLdb()`: Overwrites the SQLite database with the final, enriched data.

---

## 2. `scripts/finish.pooling.libs.py`

### High-Level Summary
This is the **second major step**, executed after the pooling has been physically performed in the lab and a "Pool Creation" file has been downloaded from Clarity. This script's main job is to **extract the official LIMS-generated Pool IDs** from that file and merge them with the local database. It then generates a comprehensive set of files for all subsequent lab processes (size selection, QC).

### Data Flow
- **Inputs:**
    - `lib_info_submitted_to_clarity.db`: The database updated by the previous script.
    - `PoolCreation_...xlsx`: The crucial input file downloaded from Clarity after pooling, which contains the official **Pool LIMS IDs**.
- **Outputs:**
    - `autofilled_PoolCreation_...xlsx`: A version of the input file filled with dummy data, ready for re-upload to Clarity to complete the step.
    - `Pool_X_transfer_file.csv`: Hamilton transfer files for creating the pools.
    - `PIPPIN_load_unload_transfer_file.csv`: A worklist for the Pippin Prep size selection instrument.
    - `FA_upload_...csv`: Input files for the Fragment Analyzer QC instrument.
    - Barcode label files (`.txt`) for tubes and plates.
    - `pool_summary.csv`: A new, central CSV file created to track the status of the pools through size selection and QC.

### Key Functions
- `addPoolClarityID()`: **The key function.** It reads the `PoolCreation_...xlsx` file and merges the official Clarity Pool IDs into the main DataFrame, linking the lab's physical work back to the script's data.
- `addPippinInfo()`: Assigns Pippin Prep cassette and lane information for size selection.
- `makePoolTransferFiles()`, `makePippinTransferFiles()`, `makeFAinputFiles()`: A series of functions that generate worklists for various lab instruments.

---

## 3. `scripts/pool.FA12.analysis.py`

### High-Level Summary
This script is the **first part of the QC and rework loop**. It analyzes the quality control data from the Fragment Analyzer (FA) after the pools have been size-selected. It applies pass/fail criteria and updates the `pool_summary.csv` to reflect which pools are successful and which need rework.

### Data Flow
- **Inputs:**
    - `pool_summary.csv`: The tracking file generated by the previous script.
    - `Smear Analysis Result.csv`: The raw data file(s) exported from the Fragment Analyzer software, located in an `Attempt_X` directory.
- **Outputs:**
    - `pool_summary.csv`: The file is **overwritten** with updated QC results, including a `pass_fail` column.
    - The raw FA file is copied and renamed for easier access.

### Key Functions
- `getFAfiles()`: Finds, validates, and renames the raw FA output files from the latest "Attempt" folder.
- **Main Logic**: Reads the FA data, filters out controls, and applies pass/fail criteria based on size distribution (`% Total` in 400-800 bp vs. 100-400 bp ranges) and concentration (`nmole/L`).
- **Merge Logic**: Merges these pass/fail results back into the `pool_summary.csv` based on FA plate and well information.

---

## 4. `scripts/rework.pooling.steps.py`

### High-Level Summary
This script is the **second part of the QC and rework loop** and acts as the workflow's central decision-maker. It reads the `pool_summary.csv` updated by the previous script and determines the next course of action.

### Data Flow & Logic
- **Input:** `pool_summary.csv` (containing the pass/fail results).
- **Logic Path A: All Pools Pass**
    - The workflow is considered complete.
    - **Outputs:**
        - `Size_selected_pools_transfer_file.csv`: A final Hamilton transfer file to move pools to their final tubes for sequencing.
        - `qPCR_pooling_form.csv`: A sheet for submitting the final pools for qPCR.
        - Final barcode label files.
- **Logic Path B: Some Pools Fail**
    - A rework iteration is triggered.
    - **Outputs:**
        - A new `Attempt_X+1` directory is created.
        - A complete new set of worklist files (Hamilton, Pippin, FA, barcodes) is generated **only for the failed pools** and placed in the new directory.
        - Pool names and tube IDs for the failed pools are automatically incremented (e.g., `1A_` -> `1B_`, `1-1_` -> `1-2_`).
        - The `pool_summary.csv` is updated by **appending** new rows for the rework attempt, ready for the next cycle.

### Key Functions
- `makeFinalPoolTransfer()`: Handles the "All Pools Pass" scenario.
- `reSizeModule()`: The core of the rework logic. It orchestrates the creation of the new attempt directory, the generation of new incremented names/barcodes, and the creation of all new worklist files for the failed pools.