#!/usr/bin/env python3
"""
Test Scripts Workflow Separately

This test focuses specifically on the scripts update detection and download:
1. Test scripts update detection with real commit differences
2. Test scripts download functionality
3. Test centralized scripts management
4. Verify script version tracking
"""

import os
import sys
import subprocess
import tempfile
import shutil
from pathlib import Path

class ScriptsWorkflowTester:
    """Test scripts workflow functionality separately."""
    
    def __init__(self):
        self.test_results = []
        self.temp_dirs = []
        self.original_dir = os.getcwd()
        
    def log_test(self, test_name: str, success: bool, details: str = ""):
        """Log test results."""
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        result = {
            "test": test_name,
            "status": status,
            "success": success,
            "details": details
        }
        self.test_results.append(result)
        print(f"{status}: {test_name}")
        if details:
            print(f"    {details}")
    
    def setup_old_scripts_scenario(self):
        """Set up scenario with old scripts to test update detection."""
        print("\nüìú Setting Up Old Scripts Scenario...")
        
        try:
            # Create temp directory for old scripts
            old_scripts_dir = tempfile.mkdtemp(prefix="old_scripts_test_")
            self.temp_dirs.append(old_scripts_dir)
            
            # Clone repo to temp directory
            clone_result = subprocess.run(
                ["git", "clone", ".", old_scripts_dir],
                capture_output=True,
                text=True,
                cwd=self.original_dir
            )
            
            if clone_result.returncode != 0:
                self.log_test("Old scripts setup", False, f"Clone failed: {clone_result.stderr}")
                return False, None
            
            # Get commit history to find an old commit
            commits_result = subprocess.run(
                ["git", "log", "--oneline", "-5"],
                capture_output=True,
                text=True,
                cwd=old_scripts_dir
            )
            
            if commits_result.returncode != 0:
                self.log_test("Get commit history", False, "Could not get commits")
                return False, None
            
            commits = commits_result.stdout.strip().split('\n')
            if len(commits) < 3:
                self.log_test("Find old commit", False, "Not enough commits")
                return False, None
            
            # Use 3rd commit back as old version
            old_commit_line = commits[2]
            old_commit_sha = old_commit_line.split()[0]
            
            # Checkout old commit
            checkout_result = subprocess.run(
                ["git", "checkout", old_commit_sha],
                capture_output=True,
                text=True,
                cwd=old_scripts_dir
            )
            
            if checkout_result.returncode != 0:
                self.log_test("Checkout old commit", False, f"Checkout failed: {checkout_result.stderr}")
                return False, None
            
            self.log_test(
                "Old scripts scenario setup",
                True,
                f"Set up old scripts at commit {old_commit_sha}"
            )
            
            return True, old_scripts_dir
                
        except Exception as e:
            self.log_test("Old scripts scenario setup", False, f"Exception: {e}")
            return False, None
    
    def test_scripts_update_detection(self, old_scripts_dir):
        """Test scripts update detection from old directory."""
        print("\nüîç Testing Scripts Update Detection...")
        
        import sys
        import os
        import subprocess
        
        try:
            # Change to old scripts directory
            os.chdir(old_scripts_dir)
            
            # Check if update_detector exists in old scripts
            update_detector_path = os.path.join(old_scripts_dir, 'src', 'update_detector.py')
            
            if not os.path.exists(update_detector_path):
                # This is realistic - old scripts don't have update detection capability
                # Use current update detector to check old vs new
                os.chdir(self.original_dir)
                
                # Import current update detector
                sys.path.insert(0, os.path.join(os.getcwd(), 'src'))
                from update_detector import UpdateDetector
                
                detector = UpdateDetector()
                
                # Get current local SHA (from old directory)
                old_local_result = subprocess.run(
                    ["git", "rev-parse", "HEAD"],
                    capture_output=True,
                    text=True,
                    cwd=old_scripts_dir
                )
                old_local_sha = old_local_result.stdout.strip() if old_local_result.returncode == 0 else None
                
                # Get current remote SHA
                remote_sha = detector.get_remote_commit_sha("analysis/esp-docker-adaptation")
                
                self.log_test(
                    "Get old local and current remote SHAs",
                    old_local_sha is not None and remote_sha is not None,
                    f"Old Local: {old_local_sha[:8] if old_local_sha else 'None'}..., Current Remote: {remote_sha[:8] if remote_sha else 'None'}..."
                )
                
                # Should detect update since old != current
                update_available = old_local_sha != remote_sha
                
                self.log_test(
                    "Scripts update detection (old vs current)",
                    update_available,
                    f"Update available: {update_available}, Old: {old_local_sha[:8] if old_local_sha else 'None'}..., Current: {remote_sha[:8] if remote_sha else 'None'}..."
                )
                
                return update_available
            else:
                # Old scripts have update detector - use it
                sys.path.insert(0, os.path.join(old_scripts_dir, 'src'))
                from update_detector import UpdateDetector
                
                detector = UpdateDetector()
                
                # Get local and remote SHAs
                local_sha = detector.get_local_commit_sha()
                remote_sha = detector.get_remote_commit_sha("analysis/esp-docker-adaptation")
                
                self.log_test(
                    "Get local and remote SHAs",
                    local_sha is not None and remote_sha is not None,
                    f"Local: {local_sha[:8] if local_sha else 'None'}..., Remote: {remote_sha[:8] if remote_sha else 'None'}..."
                )
                
                # Test scripts update detection
                scripts_result = detector.check_scripts_update("analysis/esp-docker-adaptation")
                update_available = scripts_result.get("update_available", False)
                
                # Should detect update since we're on old commit
                expected_update = local_sha != remote_sha
                
                self.log_test(
                    "Scripts update detection",
                    update_available == expected_update,
                    f"Update available: {update_available}, Expected: {expected_update}, SHAs different: {local_sha != remote_sha}"
                )
                
                # Return to original directory
                os.chdir(self.original_dir)
                
                return update_available
            
        except Exception as e:
            self.log_test("Scripts update detection test", False, f"Exception: {e}")
            os.chdir(self.original_dir)
            return False
    
    def test_scripts_download(self):
        """Test scripts download functionality."""
        print("\nüì• Testing Scripts Download...")
        
        try:
            # Create temp directory for download test
            download_dir = tempfile.mkdtemp(prefix="scripts_download_test_")
            self.temp_dirs.append(download_dir)
            
            # Import update detector
            import sys
            import os
            sys.path.insert(0, os.path.join(os.getcwd(), 'src'))
            from update_detector import UpdateDetector
            
            detector = UpdateDetector()
            
            # Test download from main branch (different from our dev branch)
            download_success = detector.download_scripts("main", download_dir)
            
            self.log_test(
                "Scripts download functionality",
                download_success,
                f"Download successful: {download_success}"
            )
            
            if download_success:
                # Verify downloaded files
                downloaded_files = list(Path(download_dir).rglob("*.py"))
                
                self.log_test(
                    "Downloaded files verification",
                    len(downloaded_files) > 0,
                    f"Downloaded {len(downloaded_files)} Python files"
                )
                
                # Check for expected files
                expected_files = ["src/core.py", "src/logic.py", "utils/docker_validation.py"]
                found_files = []
                
                for expected in expected_files:
                    if (Path(download_dir) / expected).exists():
                        found_files.append(expected)
                
                self.log_test(
                    "Expected files verification",
                    len(found_files) > 0,
                    f"Found expected files: {found_files}"
                )
            
            return download_success
            
        except Exception as e:
            self.log_test("Scripts download test", False, f"Exception: {e}")
            return False
    
    def test_centralized_scripts_management(self):
        """Test centralized scripts management functionality."""
        print("\nüè† Testing Centralized Scripts Management...")
        
        try:
            # Create temp directory to simulate user's home
            home_dir = tempfile.mkdtemp(prefix="home_test_")
            self.temp_dirs.append(home_dir)
            
            scripts_dir = os.path.join(home_dir, ".sip_lims_workflow_manager", "scripts")
            
            # Test the centralized scripts logic from run.command
            centralized_script = f'''#!/bin/bash
set -e

echo "üè† Testing centralized scripts management..."

SCRIPTS_DIR="{scripts_dir}"

# Create centralized scripts directory
mkdir -p "$SCRIPTS_DIR"
echo "üìÅ Created centralized directory: $SCRIPTS_DIR"

# Test download to centralized location
python3 src/update_detector.py --download-scripts --scripts-dir "$SCRIPTS_DIR" --branch "main" >/dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Scripts downloaded to centralized location"
    
    # Count downloaded files
    file_count=$(find "$SCRIPTS_DIR" -name "*.py" | wc -l)
    echo "üìä Downloaded $file_count Python files"
    
    # Check for key files
    if [ -f "$SCRIPTS_DIR/src/core.py" ]; then
        echo "‚úÖ Core script found"
    fi
    
    exit 0
else
    echo "‚ùå Failed to download scripts"
    exit 1
fi
'''
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.sh', delete=False) as f:
                f.write(centralized_script)
                script_path = f.name
            
            try:
                os.chmod(script_path, 0o755)
                
                result = subprocess.run(
                    ["bash", script_path],
                    capture_output=True,
                    text=True
                )
                
                print(f"    üìã Centralized management output:")
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        print(f"      {line}")
                
                management_successful = result.returncode == 0
                
                self.log_test(
                    "Centralized scripts management",
                    management_successful,
                    f"Management successful: {management_successful}"
                )
                
                # Verify centralized directory structure
                if management_successful:
                    scripts_path = Path(scripts_dir)
                    has_structure = (scripts_path / "src").exists()
                    
                    self.log_test(
                        "Centralized directory structure",
                        has_structure,
                        f"Proper structure created: {has_structure}"
                    )
                
            finally:
                os.unlink(script_path)
            
            return management_successful
            
        except Exception as e:
            self.log_test("Centralized scripts management test", False, f"Exception: {e}")
            return False
    
    def test_scripts_version_tracking(self):
        """Test scripts version tracking functionality."""
        print("\nüìä Testing Scripts Version Tracking...")
        
        try:
            # Import update detector
            import sys
            import os
            sys.path.insert(0, os.path.join(os.getcwd(), 'src'))
            from update_detector import UpdateDetector
            
            detector = UpdateDetector()
            
            # Test getting current local commit SHA
            local_sha = detector.get_local_commit_sha()
            
            self.log_test(
                "Local commit SHA detection",
                local_sha is not None,
                f"Local SHA: {local_sha[:8] if local_sha else 'None'}..."
            )
            
            # Test getting remote commit SHA
            remote_sha = detector.get_remote_commit_sha("analysis/esp-docker-adaptation")
            
            self.log_test(
                "Remote commit SHA detection",
                remote_sha is not None,
                f"Remote SHA: {remote_sha[:8] if remote_sha else 'None'}..."
            )
            
            # Test version comparison
            if local_sha and remote_sha:
                versions_different = local_sha != remote_sha
                
                self.log_test(
                    "Version comparison functionality",
                    True,  # The functionality works regardless of whether versions are different
                    f"Versions different: {versions_different}, Local: {local_sha[:8]}..., Remote: {remote_sha[:8]}..."
                )
            
            # Test update summary
            summary = detector.get_update_summary()
            
            self.log_test(
                "Update summary generation",
                summary is not None and "scripts" in summary,
                f"Summary contains scripts info: {'scripts' in summary if summary else False}"
            )
            
            return True
            
        except Exception as e:
            self.log_test("Scripts version tracking test", False, f"Exception: {e}")
            return False
    
    def cleanup_test_artifacts(self):
        """Clean up test artifacts."""
        print("\nüßΩ Cleaning up test artifacts...")
        
        for temp_dir in self.temp_dirs:
            try:
                shutil.rmtree(temp_dir)
                print(f"    Cleaned up: {temp_dir}")
            except Exception as e:
                print(f"    Warning: Could not clean up {temp_dir}: {e}")
    
    def run_scripts_workflow_test(self):
        """Run scripts workflow test."""
        print("üéØ Starting Scripts Workflow Test")
        print("=" * 70)
        print("This test focuses specifically on scripts functionality:")
        print("1. Set up old scripts scenario with real commit differences")
        print("2. Test scripts update detection")
        print("3. Test scripts download functionality")
        print("4. Test centralized scripts management")
        print("5. Test scripts version tracking")
        print("=" * 70)
        
        try:
            # Step 1: Set up old scripts scenario
            success, old_scripts_dir = self.setup_old_scripts_scenario()
            if not success:
                print("‚ùå Could not set up old scripts scenario")
                return False
            
            # Step 2: Test scripts update detection
            self.test_scripts_update_detection(old_scripts_dir)
            
            # Step 3: Test scripts download
            self.test_scripts_download()
            
            # Step 4: Test centralized scripts management
            self.test_centralized_scripts_management()
            
            # Step 5: Test scripts version tracking
            self.test_scripts_version_tracking()
            
        finally:
            # Always clean up
            self.cleanup_test_artifacts()
        
        # Generate summary report
        print("\n" + "=" * 70)
        print("üìä SCRIPTS WORKFLOW TEST SUMMARY")
        print("=" * 70)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result["success"])
        failed_tests = total_tests - passed_tests
        
        print(f"Total Tests: {total_tests}")
        print(f"Passed: {passed_tests} ‚úÖ")
        print(f"Failed: {failed_tests} ‚ùå")
        print(f"Success Rate: {(passed_tests/total_tests)*100:.1f}%")
        
        if failed_tests > 0:
            print("\n‚ùå FAILED TESTS:")
            for result in self.test_results:
                if not result["success"]:
                    print(f"  - {result['test']}: {result['details']}")
        
        print("\nüéØ OVERALL RESULT:", "‚úÖ SCRIPTS WORKFLOW VERIFIED" if failed_tests == 0 else "‚ö†Ô∏è  SCRIPTS WORKFLOW TESTED")
        
        return failed_tests == 0

if __name__ == "__main__":
    tester = ScriptsWorkflowTester()
    success = tester.run_scripts_workflow_test()
    sys.exit(0 if success else 1)